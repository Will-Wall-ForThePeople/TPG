import pandas as pd
import logging, pytz, io, os
from azure.identity import ManagedIdentityCredential, AzureCliCredential, ClientSecretCredential
from azure.keyvault.secrets import SecretClient
from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient
from datetime import datetime, timedelta
from io import StringIO
from dotenv import load_dotenv

load_dotenv()

# Set up logging to both a file and the console
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.FileHandler("debug.log"),
        logging.StreamHandler()
    ]
)

# Convert UTC timestamp string to US Eastern Time
def convert_to_est(utc_time_str):
    utc_time = datetime.strptime(utc_time_str, "%Y-%m-%dT%H:%M:%S.%fZ")
    utc_time = utc_time.replace(tzinfo=pytz.UTC)
    est = pytz.timezone("US/Eastern")
    est_time = utc_time.astimezone(est)
    return est_time.strftime('%Y-%m-%d %H:%M:%S')

def save_csv(container_client, df, path):

        csv_buffer = StringIO()
        df.to_csv(csv_buffer, index=False, float_format='%.2f')
        csv_data = csv_buffer.getvalue().encode('utf-8-sig')
        blob_client = container_client.get_blob_client(path)
        blob_client.upload_blob(csv_data, overwrite=True)

def get_credential(enable_probe: bool = True):
    logger = logging.getLogger("auth")
    scope = "https://vault.azure.net/.default"
    try:
        mi = ManagedIdentityCredential()
        # probe a simple token request to confirm MI works (optional)
        if enable_probe:
            mi.get_token(scope)  # probe token
            logger.info("ManagedIdentityCredential selected (token probe OK).")
        else:
            logger.info("ManagedIdentityCredential selected (probe disabled).")
        return mi
    except Exception:
        pass

    try:
        cli = AzureCliCredential()
        if enable_probe:
            cli.get_token(scope)
            logger.info("AzureCliCredential selected (token probe OK).")
        else:
            logger.info("AzureCliCredential selected (probe disabled).")

        return cli
    except Exception:
        pass

def get_blob_service_client():
    """
    Primary path: fetch connection string from Key Vault.
    Fallback: use local dev connection string from env.
    """
    # Local dev override: direct connection string
    conn = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
    if conn:
        return BlobServiceClient.from_connection_string(conn)

    # Otherwise, use Key Vault to fetch the connection string
    credential = get_credential()
    azure_vault_url = 'https://mm-ccc-project-team-kv.vault.azure.net/'

    secret_client = SecretClient(vault_url=azure_vault_url, credential=credential)
    # Secret name expected: "azure-connection-string"
    connection_string = secret_client.get_secret("azure-connection-string").value
    return BlobServiceClient.from_connection_string(connection_string)

# Azure setup
blob_service_client = get_blob_service_client()
container_client = blob_service_client.get_container_client("tpg-data")

# Download the blob data
tpg_blob = container_client.get_blob_client("MM_173_TPG_DATA")
tpg_data = tpg_blob.download_blob().readall()
tpg_df = pd.read_parquet(io.BytesIO(tpg_data), engine="pyarrow")

print("Rows:", len(tpg_df))

tpg_df = tpg_df.rename(columns={"EVALUATION_DATE":"Evaluation Date", "AGENT":"Agent", "AGENTEMAIL":"AgentEmail", "SUPERVISOR":"Supervisor","BEHAVIOR_EXT":"Behavior Text","RESPONSE":"Response", "ISOPPORTUNITY":"IsOpportunity", "ISDEFECT":"IsDefect"})
columns_to_keep = ["Evaluation Date", "Agent", "AgentEmail","Supervisor", "Behavior Text", "Response", "IsOpportunity", "IsDefect"]
tpg_df = tpg_df[columns_to_keep]

tpg_df["Date"] = pd.to_datetime(tpg_df["Evaluation Date"], errors="coerce")
print(tpg_df)

target_behaviors = [
    "Builds rapport by engaging customer",
    "Confirms customer's satisfaction with call outcome",
    "Maintains call control to guide conversation",
    "Personalizes call by using customer's name",
    "Takes ownership & displays willingness to help"
]

filtered_df = tpg_df[tpg_df['Behavior Text'].isin(target_behaviors)]

behavior_stats = filtered_df.groupby(['Date', 'Agent', 'Behavior Text'], as_index=False).agg({'IsDefect': 'sum','IsOpportunity': 'sum'}).reset_index()
behavior_stats['IsDefect'] = pd.to_numeric(behavior_stats['IsDefect'], errors='coerce')
behavior_stats['IsOpportunity'] = pd.to_numeric(behavior_stats['IsOpportunity'], errors='coerce')
behavior_stats['DefectRate'] = behavior_stats['IsDefect'] / behavior_stats['IsOpportunity'].round(2)

totals = tpg_df.groupby(['Date', 'Agent'], as_index=False).agg({'IsDefect': 'sum','IsOpportunity': 'sum'}).reset_index()
totals['IsDefect'] = pd.to_numeric(totals['IsDefect'], errors='coerce')
totals['IsOpportunity'] = pd.to_numeric(totals['IsOpportunity'], errors='coerce')
totals['DefectRate'] = (totals['IsDefect'] / totals['IsOpportunity']).round(2)
totals = totals[['Agent', 'DefectRate']]

behavior_pivot = behavior_stats.pivot_table(index='Agent',columns='Behavior Text',values='DefectRate',aggfunc='first').round(2)
behavior_pivot = behavior_pivot.reset_index()

delight_df = tpg_df[tpg_df['Behavior Text'] == "Customer demeanor at end of call"]
delight_df["Response"] = delight_df["Response"].astype(str).str.strip()

delight_counts = (delight_df.groupby(['Date', "Agent", "Response"], dropna=False).size().unstack("Response", fill_value=0).reset_index())
delight_counts['Delight'] = delight_counts['Audibly happy'] / (delight_counts[['Audibly happy', 'Neutral', 'Irate']].sum(axis=1))
delight_counts['Delight'] = delight_counts['Delight'].round(2)
delight_counts = delight_counts[['Agent', 'Delight']]

tpg_df = tpg_df[["Evaluation Date", "Agent", "AgentEmail","Supervisor"]]
df_unique = tpg_df.drop_duplicates(subset=['Agent'])

final_df = (df_unique.merge(behavior_pivot, on='Agent', how='left').merge(totals, on='Agent', how='left').merge(delight_counts, on='Agent', how='left'))

storage_container = blob_service_client.get_container_client('centrical-data')
storage_path = f"TPG/CENTRICAL_TPG.csv"

save_csv(storage_container, final_df, storage_path)
